# Design: CLEAR Framework Integration

## Architecture Overview

### Current Architecture
```
User Input â†’ PromptOptimizer.analyze() â†’ Regex Pattern Matching â†’ Output
                     â†“
          { gaps, ambiguities, strengths, suggestions }
```

### New Architecture
```
User Input â†’ PromptOptimizer.applyCLEARFramework() â†’ CLEAR Analysis â†’ Output
                     â†“
          { conciseness, logic, explicitness, adaptiveness, reflectiveness }
                     â†“
          Mapped to existing categories for compatibility
```

## CLEAR Framework Components

### 1. Concise (C)
**Purpose:** Eliminate verbosity, remove pleasantries, focus on essentials

**Implementation:**
- Detect unnecessary words (please, could you, etc.)
- Count vague qualifiers (maybe, perhaps, might)
- Measure signal-to-noise ratio
- Suggest specific replacements

**Maps to:** Ambiguities (partial overlap)

### 2. Logical (L)
**Purpose:** Ensure coherent sequencing and structured flow

**Implementation:**
- Analyze order of requirements
- Detect jumbled concepts
- Suggest logical reordering (context â†’ requirements â†’ constraints â†’ output)
- Validate step-by-step sequences

**Maps to:** New category (structural improvement)

### 3. Explicit (E)
**Purpose:** Provide clear output specifications

**Implementation:**
- Check for persona/role specification
- Verify output format is defined
- Ensure tone/style is specified
- Validate success criteria present
- Check for examples when helpful

**Maps to:** Gaps (directly maps)

### 4. Adaptive (A)
**Purpose:** Provide flexibility and alternative approaches

**Implementation:**
- Generate 2-3 alternative phrasings
- Suggest different prompt structures (user story, job story, structured sections)
- Recommend temperature/creativity settings
- Provide variation examples

**Maps to:** Deep mode only (suggestions with examples)

### 5. Reflective (R)
**Purpose:** Enable continuous evaluation and validation

**Implementation:**
- Create accuracy verification checklist
- Identify edge cases to consider
- Perform "what could go wrong" analysis
- Suggest fact-checking steps
- Provide quality assessment criteria

**Maps to:** Deep mode only (new category)

## Mode Differentiation Strategy

### Fast Mode: C + L + E + Triage
**Purpose:** Quick cleanup for "shitty prompts"

**CLEAR Usage:**
- âœ… Concise: Remove fluff, tighten language
- âœ… Logical: Check basic sequencing
- âœ… Explicit: Ensure key specs present
- âŒ Adaptive: Recommend deep mode instead
- âŒ Reflective: Basic validation only

**Output:**
```
ğŸ¯ CLEAR Analysis (Fast Mode)
â”œâ”€ Conciseness: [score + issues]
â”œâ”€ Logic: [score + flow issues]
â”œâ”€ Explicitness: [score + missing specs]
â”œâ”€ ğŸ’¡ Recommendation: Use /clavix:deep for adaptive variations
â””â”€ âœ¨ Improved Prompt
   â””â”€ ğŸ“ Changes Made: [educational summary]
```

### Deep Mode: Full CLEAR (C + L + E + A + R)
**Purpose:** Comprehensive analysis for complex requirements

**CLEAR Usage:**
- âœ… Concise: Detailed verbosity analysis
- âœ… Logical: Comprehensive flow analysis
- âœ… Explicit: Complete specification check
- âœ… Adaptive: Multiple variations + alternatives
- âœ… Reflective: Full validation checklist + edge cases

**Output:**
```
ğŸ¯ CLEAR Framework Deep Analysis

ğŸ“Š Framework Assessment:
â”œâ”€ Concise: [score + detailed analysis]
â”œâ”€ Logical: [score + structure analysis]
â”œâ”€ Explicit: [score + completeness check]
â”œâ”€ Adaptive: [score + flexibility analysis]
â””â”€ Reflective: [score + quality validation]

âœ¨ Improved Prompt (CLEAR-optimized)
   â””â”€ ğŸ“ Changes Made: [educational summary]

ğŸ”„ Adaptive Variations (A):
â”œâ”€ Variation 1: [different approach]
â”œâ”€ Variation 2: [different framing]
â””â”€ Variation 3: [different structure]

ğŸ¤” Reflection Checklist (R):
â”œâ”€ Accuracy verification steps
â”œâ”€ Edge cases to consider
â”œâ”€ Potential issues (what could go wrong)
â””â”€ Success criteria validation
```

## Implementation Plan

### Phase 1: Core Engine
**File:** `src/core/prompt-optimizer.ts`

**New Methods:**
```typescript
// Individual CLEAR component analyzers
analyzeConciseness(prompt: string): ConciseAnalysis
analyzeLogic(prompt: string): LogicAnalysis
analyzeExplicitness(prompt: string): ExplicitAnalysis
analyzeAdaptiveness(prompt: string): AdaptiveAnalysis
analyzeReflectiveness(prompt: string): ReflectiveAnalysis

// Orchestrator
applyCLEARFramework(prompt: string, mode: 'fast' | 'deep'): CLEARResult

// Scoring
getCLEARScore(analysis: CLEARResult): CLEARScore
```

**Backward Compatibility:**
```typescript
// Keep existing methods, map them internally
analyze(prompt: string): Analysis {
  const clear = this.applyCLEARFramework(prompt, 'fast');
  return this.mapCLEARToLegacy(clear);
}

mapCLEARToLegacy(clear: CLEARResult): Analysis {
  return {
    gaps: clear.explicitness.issues,
    ambiguities: clear.conciseness.issues,
    strengths: clear.scores,
    suggestions: [...clear.logic.suggestions, ...clear.conciseness.suggestions]
  };
}
```

### Phase 2: Template Updates
**Files:** `src/templates/slash-commands/claude-code/*.md`

**Changes:**
- Add CLEAR framework explanation to each command
- Reference C, L, E, A, R components
- Update examples to show CLEAR-based output

### Phase 3: Documentation
**Files:** `README.md`, `CLAUDE.md`

**Changes:**
- Hero section: "Built on the CLEAR Framework"
- Features section: Replace "rule-based" with "CLEAR Framework methodology"
- New section: "Why CLEAR?" with academic citation
- Update command descriptions

## Trade-offs

### Option 1: Replace Existing Analysis (Chosen)
**Pros:**
- Clean, unified methodology
- Modern, research-backed approach
- Easy to explain and document

**Cons:**
- Risk of regression if CLEAR implementation is inferior
- Breaking change if output format changes significantly

**Mitigation:** Map CLEAR to existing categories, preserve output structure

### Option 2: Keep Both Systems
**Pros:**
- Zero risk of regression
- Users can choose methodology

**Cons:**
- Code complexity doubles
- Confusing for users (which to use?)
- Maintenance burden

**Decision:** Option 1 with backward compatibility mapping

### Option 3: CLEAR as Optional Flag
**Pros:**
- Gradual migration
- A/B testing capability

**Cons:**
- Fragmented user experience
- Doubles test surface area
- Eventually need to deprecate old system anyway

**Decision:** Not chosen - commit to CLEAR as the standard

## Validation Strategy

### Testing Approach
1. **Unit Tests:** Each CLEAR component analyzer
2. **Integration Tests:** Full applyCLEARFramework() with real prompts
3. **Regression Tests:** Compare CLEAR vs old system on existing test suite
4. **Quality Tests:** Ensure CLEAR output â‰¥ old system quality

### Test Prompts
- **Poor Conciseness:** "Could you please maybe help me with creating something like a login page if possible?"
- **Poor Logic:** Jumbled requirements without sequencing
- **Poor Explicitness:** "Build a dashboard" (no specs)
- **Needs Adaptiveness:** Open-ended feature request with multiple valid approaches
- **Needs Reflection:** Complex prompt requiring validation

## Open Questions
None - design is complete and ready for implementation.
